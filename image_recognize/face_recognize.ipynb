{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n",
      "face is detected.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from scipy import ndimage\n",
    "\n",
    "cap = cv2.VideoCapture('movie6.MOV') # iPhoneだと1920 times 1080\n",
    "RATIO = 2.0 \n",
    "\n",
    "FIRST_THREAD_COUNT = threading.activeCount() # 起動時のスレッド数（自分の環境だとなぜか5）\n",
    "\n",
    "class FaceThread(threading.Thread): # スレッド処理をするクラス\n",
    "    def __init__(self,frame):\n",
    "        super(FaceThread, self).__init__()\n",
    "        self._cascade_path = \"haarcascades/haarcascade_frontalface_default.xml\"\n",
    "        self._frame = frame\n",
    "        \n",
    "    def run(self):\n",
    "        self._gray = cv2.cvtColor(self._frame,cv2.COLOR_BGR2GRAY)\n",
    "        self._cascade = cv2.CascadeClassifier(self._cascade_path)\n",
    "        self._gray = cv2.equalizeHist(self._gray)\n",
    "        self._face = self._cascade.detectMultiScale(self._gray,scaleFactor = 1.1,minNeighbors = 5,minSize = (100,100))\n",
    "        \n",
    "        if len(self._face) > 0:\n",
    "            print(\"face is detected.\")\n",
    "            self._color = (255,0,0)\n",
    "            for self._rect in self._face:\n",
    "                cv2.rectangle(self._frame,tuple(self._rect[0:2]),tuple(self._rect[0:2] + self._rect[2:4]),self._color,thickness = 2)\n",
    "                \n",
    "            # 現在時間を名前に付けて写真を保存\n",
    "            self._now = datetime.now().strftime(\"%Y%m%d-%H%M%S%f\")\n",
    "            self._image_path = \"capture/\" + self._now + \".jpg\"\n",
    "            cv2.imwrite(self._image_path,self._frame)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == 0:\n",
    "        break\n",
    "    height = int(frame.shape[0])\n",
    "    width = int(frame.shape[1])\n",
    "    resized_frame = cv2.resize(frame,(int(width/RATIO),int(height/RATIO))) # 動画のサイズを1/RATIOにする\n",
    "    \n",
    "    resized_frame = ndimage.rotate(resized_frame,270,reshape = False)\n",
    "    resized_frame = resized_frame[0:int(width/(3 * RATIO)),:]\n",
    "\n",
    "    #cv2.imshow(\"movie\",resized_frame)\n",
    "    \n",
    "    #別スレッドが既に立ち上がっていなければ，別スレッド開始\n",
    "    if(threading.activeCount() == FIRST_THREAD_COUNT): \n",
    "        th = FaceThread(resized_frame)\n",
    "        th.start()\n",
    "        \n",
    "    c = cv2.waitKey(100) # ここに顔認識されるフレーム数が依存（つらい）\n",
    "    if(c == 27):\n",
    "        break # ESCで抜ける\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
